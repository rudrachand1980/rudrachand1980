caption="source: mpg") +
theme(axis.text.x = element_text(angle=65, vjust=0.6))
###
table(data2$ServerID)
####lets convert to time series
#Monthly time series
data_monthly <- ts(data_server_gisalpnbumstr1$Priority,start = c(2017,10),end =c(2018,6),frequency = 12)
###lets analyse ServerID = gisalpnbumstr1 ,which has more number of tickets
###filtering the serverid which has more number of tickets
data_server_gisalpnbumstr1 <- filter(data2,data2$ServerID == 'gisalpnbumstr1')
####lets convert to time series
#Monthly time series
data_monthly <- ts(data_server_gisalpnbumstr1$Priority,start = c(2017,10),end =c(2018,6),frequency = 12)
data_monthly
####lets convert to time series
#Monthly time series
data_monthly <- ts(data_server_gisalpnbumstr1$Priority,start = c(2017,10),end =c(2018,7),frequency = 12)
data_monthly ##we have 9 data points
View(data_server_gisalpnbumstr1)
####lets convert to time series
#Monthly time series
data_monthly <- ts(data_server_gisalpnbumstr1$Priority,start = c(2017,10),end =c(2018,6),frequency = 12)
data_monthly ##we have 9 data points
##plot the monthly dataset
plot.ts(data_monthly)
#lets start analysing Weekly.we should take week starting from october 2017
ts_gisalpnbumstr1 <- ts(data_server_gisalpnbumstr1$INC_Count,start = c(2017,41),frequency = 52)
ts_gisalpnbumstr1
##plot the time series
plot.ts(ts_gisalpnbumstr1)
##plot the monthly dataset
plot.ts(data_monthly)
##plot the time series
plot.ts(ts_gisalpnbumstr1)
install.packages("ttr")
install.packages("TTR")
#load lib
library(TTR)
install.packages("TTR")
#load lib
library(TTR)
###LETS DO Simple moving average method(SMA)
####smooth according to SMA function for last 3 period
data_weekly_sma3 <- SMA(ts_gisalpnbumstr1,3)
plot(data_weekly_sma3)
plot.ts(data_weekly_sma3)
forecast(data_weekly_sma3)
library('ggplot2') # visualization
library('ggthemes') # visualization
library('scales') # visualization
library('grid') # visualisation
library('gridExtra') # visualisation
library('corrplot') # visualisation
library('ggrepel') # visualisation
library('RColorBrewer') # visualisation
library('data.table') # data manipulation
library('dplyr') # data manipulation
library('readr') # data input
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('lazyeval') # data wrangling
library('broom') # data wrangling
library('stringr') # string manipulation
library('purrr') # string manipulation
library('forcats') # factor manipulation
library('lubridate') # date and time
library('forecast') # time series analysis
library('prophet') # time series analysis
library('zoo')
library('tseries')
###LETS DO Simple moving average method(SMA)
####smooth according to SMA function for last 3 period
data_weekly_sma3 <- SMA(ts_gisalpnbumstr1,3)
plot.ts(data_weekly_sma3)
forecast(data_weekly_sma3)
data_weekly_sma3
forecast(data_weekly_sma3)
plot(data_weekly_sma3)
##smooth according to SMA function for last 5 period
data_weekly_sma5 <- SMA(ts_gisalpnbumstr1,5)
plot(data_weekly_sma5)
forecast(data_weekly_sma5)
plot.ts(data_weekly_sma5)
forecast(data_weekly_sma5)
# 209       1.500915 0.8841571 2.117674  0.5576650 2.444166
# 210       1.551370 0.7729112 2.329830  0.3608198 2.741921
# 211       1.601826 0.6757888 2.527862  0.1855745 3.018077
# 212       1.652281 0.5860324 2.718529  0.0215946 3.282967
# 213       1.702736 0.5002454 2.905226 -0.1363146 3.541786
# 214       1.753191 0.4164390 3.089943 -0.2911948 3.797577
# 215       1.803646 0.3333281 3.273964 -0.4450113 4.052304
# 216       1.854101 0.2500212 3.458181 -0.5991275 4.307330
# 217       1.904556 0.1658652 3.643248 -0.7545424 4.563655
###transforming the time series in case of seasonal and random fluctuations
weekly_ts_gisalpnbumstr1_log <- log(ts_gisalpnbumstr1)
plot.ts(weekly_ts_gisalpnbumstr1_log)
weekly_ts_gisalpnbumstr1_log
forecast(weekly_ts_gisalpnbumstr1_log)
exp(forecast(weekly_ts_gisalpnbumstr1_log))
coef(exp(forecast(weekly_ts_gisalpnbumstr1_log)))
forecast(weekly_ts_gisalpnbumstr1_log)
##exponential moving average
data_ema3_25 <- EMA(ts_gisalpnbumstr1,3,ratio = 0.25)
plot(data_ema3_25)
plot.ts(data_ema3_25)
forecast(data_ema3_25)
data_ema3_25
data_ema3_50 <- EMA(ts_gisalpnbumstr1,3,ratio = 0.5)
plot.ts(orderval_ema3_50)
data_ema3_50
forecast(data_ema3_50)
# 208       1.635193  0.74122303 2.529164  0.2679838  3.002403
# 209       1.770184  0.39729347 3.143074 -0.3294707  3.869838
# 210       1.905174  0.08269151 3.727657 -0.8820725  4.692421
# 211       2.040165 -0.23699238 4.317321 -1.4424464  5.522775
# 212       2.175155 -0.57575581 4.926066 -2.0320000  6.382310
# 213       2.310145 -0.94181562 5.562106 -2.6632998  7.283591
# 214       2.445136 -1.34120290 6.231474 -3.3455695  8.235841
# 215       2.580126 -1.77904523 6.939298 -4.0866512  9.246904
# 216       2.715117 -2.26013383 7.690367 -4.8938723 10.324106
# 217       2.850107 -2.78921701 8.489431 -5.7744948 11.474709
data_ema3_75 <- EMA(ts_gisalpnbumstr1,3,ratio = 0.75)
plot(data_ema3_75)
plot.ts(data_ema3_75)
forecast(data_ema3_75)
# From the above Simple and Exponential moving average ,
# we can see less -ve value in data_ema3_25 dataset, which result can be validated
autoplot(data_ema3_25)
install.packages("fpp2")
library(fpp2)
libr
library('fpp2')
# From the above Simple and Exponential moving average ,
# we can see less -ve value in data_ema3_25 dataset, which result can be validated
autoplot(data_ema3_25)
# From the above Simple and Exponential moving average ,
# we can see less -ve value in data_ema3_25 dataset, which result can be validated
plot(data_ema3_25)
# From the above Simple and Exponential moving average ,
# we can see less -ve value in data_ema3_25 dataset, which result can be validated
plot(forecast(data_ema3_25))
# From the above Simple and Exponential moving average ,
# we can see less -ve value in data_ema3_25 dataset, which result can be validated
plot(forecast(data_ema3_25,h=65))
forecast(data_ema3_25,h=65)
# From the above Simple and Exponential moving average ,
# we can see less -ve value in data_ema3_25 dataset, which result can be validated
plot(forecast(data_ema3_25,h=20))
#Lets decompose the data to see the seasonal or trend if exists
decompose_ts_gisalpnbumstr1 <- decompose(ts_gisalpnbumstr1)
plot(decompose_ts_gisalpnbumstr1)
###From the plot , it can be seen there exists some randomness but
#it is not clear if there exists seasonal, and there is no trend atall
dataset_remove_random  <-  ts_gisalpnbumstr1 - decompose_ts_gisalpnbumstr1$random
plot(dataset_remove_random)
dataset_remove_random
plot.ts(dataset_remove_random)
plot(dataset_remove_random)
plot(dataset_remove_random)
###lets remove seasonal
dataset_remove_seasonal <- ts_gisalpnbumstr1 - decompose_ts_gisalpnbumstr1$seasonal
plot(dataset_remove_seasonal)
#lets forecast the data assuming it is stationary now
forecast(dataset_remove_seasonal)
#lets forecast the data assuming it is stationary now
plot(forecast(dataset_remove_seasonal))
#lets forecast the data assuming it is stationary now
plot(forecast(dataset_remove_seasonal,h=20))
#lets forecast the data assuming it is stationary now
forecast(dataset_remove_seasonal,h=20)
##lets do ARIMA Model and see the result
##lets do stationary check
adf.test(ts_gisalpnbumstr1,alternative = "stationary")
###Plot ACF and PACF
acf(ts_gisalpnbumstr1)
pacf(ts_gisalpnbumstr1)
ts_gisalpnbumstr1_seasonal
####auto arima
auto.arima(ts_gisalpnbumstr1)
# Series: ts_gisalpnbumstr1
# ARIMA(1,0,2) with non-zero mean
#
# Coefficients:
#   ar1      ma1      ma2    mean
# 0.8827  -0.4992  -0.2344  2.0739
# s.e.  0.0750   0.1015   0.0714  0.3215
#
# sigma^2 estimated as 4.372:  log likelihood=-444.5
# AIC=899.01   AICc=899.31   BIC=915.67
auto.arima(ts_gisalpnbumstr1,test = c("kpss", "adf", "pp"))
####auto arima
auto.arima(ts_gisalpnbumstr1,test = c("kpss", "adf", "pp")) #  ==> p=1,d=0,q=2
# Series: ts_gisalpnbumstr1
# ARIMA(1,0,2) with non-zero mean
#
# Coefficients:
#   ar1      ma1      ma2    mean
# 0.8827  -0.4992  -0.2344  2.0739
# s.e.  0.0750   0.1015   0.0714  0.3215
#
# sigma^2 estimated as 4.372:  log likelihood=-444.5
# AIC=899.01   AICc=899.31   BIC=915.67
model_arima_ts_gisalpnbumstr1 <- auto.arima(ts_gisalpnbumstr1,test = c("kpss", "adf", "pp"))
forecast(model_arima_ts_gisalpnbumstr1)
forecast(model_arima_ts_gisalpnbumstr1,h=10)
# 2021.769       1.785505 -1.0845171 4.655527 -2.603815 6.174824
# 2021.788       1.819340 -1.0642118 4.702893 -2.590672 6.229353
# 2021.808       1.849207 -1.0448437 4.743257 -2.576861 6.275275
# 2021.827       1.875570 -1.0266342 4.777773 -2.562968 6.314107
# 2021.846       1.898840 -1.0097008 4.807380 -2.549389 6.347069
# 2021.865       1.919380 -0.9940881 4.832848 -2.536385 6.375145
# 2021.885       1.937511 -0.9797908 4.854813 -2.524117 6.399139
# 2021.904       1.953515 -0.9667704 4.873800 -2.512676 6.419706
# 2021.923       1.967641 -0.9549663 4.890249 -2.502101 6.437384
###ARIMA also predicted ticket count in year 2021 comes 5 to 6 range
plot(model_arima_ts_gisalpnbumstr1)
# 2021.769       1.785505 -1.0845171 4.655527 -2.603815 6.174824
# 2021.788       1.819340 -1.0642118 4.702893 -2.590672 6.229353
# 2021.808       1.849207 -1.0448437 4.743257 -2.576861 6.275275
# 2021.827       1.875570 -1.0266342 4.777773 -2.562968 6.314107
# 2021.846       1.898840 -1.0097008 4.807380 -2.549389 6.347069
# 2021.865       1.919380 -0.9940881 4.832848 -2.536385 6.375145
# 2021.885       1.937511 -0.9797908 4.854813 -2.524117 6.399139
# 2021.904       1.953515 -0.9667704 4.873800 -2.512676 6.419706
# 2021.923       1.967641 -0.9549663 4.890249 -2.502101 6.437384
###ARIMA also predicted ticket count in year 2021 comes 5 to 6 range
plot(forecast(model_arima_ts_gisalpnbumstr1))
##lets see the residuals(error rate)
model_arima_ts_gisalpnbumstr1$residuals
install.packages("dplyr")
library(dplyr)
install.packages("readxl")
library(readxl)
install.packages("readxl")
install.packages("readxl")
library(readxl)
library(readxl)
Qliksense_license_utilization_input <- read_excel("C:/Users/user/Desktop/Qliksense_license_utilization_input.xlsx")
View(Qliksense_license_utilization_input)
data1 <- Qliksense_license_utilization_input
head(data1)
mutate(diff_day_count=round(c(NA,diff(data1$InsertDate)),1)
wdw
data1 %>% group_by(data1$USER_NAME) %>%
mutate(diff_day_count=round(c(NA,diff(data1$InsertDate)),1)
data1 %>% group_by(data1$USER_NAME) %>%  mutate(diff_day_count=round(c(NA,diff(data1$InsertDate)),1)
as.Date(data1$InsertDate)
data1$ReportID <- as.Date(data1$InsertDate)
data1 %>% group_by(data1$USER_NAME) %>%  mutate(diff_day_count=round(c(NA,diff(data1$InsertDate)),1)
jjj
data1 %>% group_by(data1$USER_NAME) %>%
mutate(gap=round(c(NA,diff(data1$InsertDate)), 1))
data1 %>% group_by(data1$USER_NAME) %>%
mutate(gap=round(c(NA,diff(data1$InsertDate)), 1))
library(dplyr)
data1 %>% group_by(data1$USER_NAME) %>%
mutate(gap=round(c(NA,diff(data1$InsertDate)), 1))
library(dplyr)
library(readxl)
data1$ReportID <- as.Date(data1$InsertDate)
data1 <- Qliksense_license_utilization_input
library(dplyr)
library(readxl)
data1 <- Qliksense_license_utilization_input
head(data1)
data1$ReportID <- as.Date(data1$InsertDate)
data1 %>% group_by(data1$USER_NAME) %>%
mutate(gap=round(c(NA,diff(data1$InsertDate)), 1))
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap=round(c(NA,diff(data1$InsertDate)), 1))
View(data1)
View(Qliksense_license_utilization_input)
library(readxl)
Qliksense_license_utilization_input <- read_excel("C:/Users/user/Desktop/Qliksense_license_utilization_input.xlsx")
View(Qliksense_license_utilization_input)
library(dplyr)
data1 <- Qliksense_license_utilization_input
head(data1)
data1$InsertDate <- as.Date(data1$InsertDate)
View(data1)
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap=round(c(NA,diff(data1$InsertDate)), 1))
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap_time=round(c(NA,diff(data1$InsertDate)), 1))
data1 %>% group_by(data1$USER_NAME)
View(Qliksense_license_utilization_input)
round(c(NA,diff(data1$InsertDate))
ijuoih
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap_time=round(c(NA,diff(data1$InsertDate)), 1))
str(data1)
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap_time=round(c(NA,diff(data1$InsertDate)), 1)
dfedf
data1 %>% group_by(data1$USER_NAME)
time = c('09/09/15 0:37:45', '09/09/15 0:39:45', '09/09/15 1:39:15', '09/10/15'20:35:20, '09/10/15 20:45:40', '09/10/15 20:47:00', '09/10/15 21:47:00' ,'09/11/15 7:15:15', '09/11/15 17:15:30')
db = (name = c('A','A','A', 'B','B','B','B', 'C','C'),
time = c('09/09/15 0:37:45', '09/09/15 0:39:45', '09/09/15 1:39:15', '09/10/15'20:35:20, '09/10/15 20:45:40', '09/10/15 20:47:00', '09/10/15 21:47:00' ,'09/11/15 7:15:15', '09/11/15 17:15:30')
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap_time=round(c(0,diff(data1$InsertDate)), 1)
,hkgtjuf
khjughug
View(data1)
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap=round(c(0,diff(data1$InsertDate)), 1)
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap=round(c(0,diff(data1$InsertDate)),1)
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap=round(c(0,diff(data1$InsertDate)),1)
hjjhughyg
library(readxl)
Qliksense_license_utilization_input <- read_excel("C:/Users/user/Desktop/Qliksense_license_utilization_input.xlsx")
View(Qliksense_license_utilization_input)
library(dplyr)
data1 <- Qliksense_license_utilization_input
head(data1)
str(data1)
data1$USER_NAME  <- as.factor(data1$USER_NAME)
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap=round(c(0,diff(data1$InsertDate)),1)
ww
data1 %>% group_by(data1$USER_NAME) %>%
mutate(gap=round(c(0,diff(data1$InsertDate)),1)
data1 %>% group_by(data1$USER_NAME) %>%
mutate(gap=round(c(NA,diff(data1$InsertDate)),1)
qswq
data1 %>% group_by(data1$USER_NAME) %>%
mutate(gap=round(c(NA,diff(data1$InsertDate)),1)
hghgy
library(dplyr)
library(readxl)
data1 <- Qliksense_license_utilization_input
head(data1)
str(data1)
data1$InsertDate <- as.Date(data1$InsertDate)
head(data1)
data1$USER_NAME  <- as.factor(data1$USER_NAME)
str(data1)
head(data1)
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap=round(c(NA,diff(data1$InsertDate)),1))
data1 %>% group_by(data1$UserID) %>%  mutate(gap=round(c(NA,diff(data1$InsertDate)),1))
data1 %>% group_by(data1$UserID) %>%  mutate(c1=round(c(NA,diff(data1$InsertDate)),1))
data1 %>% group_by(data1$USER_NAME) %>%  mutate(c1=round(c(NA,diff(data1$InsertDate)),1))
data1 %>% group_by(data1$USER_NAME) %>%  mutate(gap=round(c(NA,diff(data1$InsertDate)),1))
data1 %>% group_by(USER_NAME) %>%  mutate(gap=round(c(NA,diff(InsertDate)),1))
rm(Qliksense_license_utilization_input)
library(dplyr)
library(readxl)
data1 <- Qliksense_license_utilization_input
head(data1)
str(data1)
data1$InsertDate <- as.Date(data1$InsertDate)
data1$USER_NAME  <- as.factor(data1$USER_NAME)
data1 %>% group_by(USER_NAME) %>%  mutate(gap=round(c(NA,diff(InsertDate)),1))
data1 %>% group_by(USER_NAME) %>%  mutate(gap=round(c(0,diff(InsertDate)),1))
data1 %>% group_by(USER_NAME) %>%  mutate(gap=round(c(NA,diff(InsertDate)),1))
data1 <-data1 %>% group_by(USER_NAME) %>%  mutate(gap=round(c(NA,diff(InsertDate)),1))
data1 %>% group_by(USER_NAME) %>%  mutate(gap=round(c(NA,diff(InsertDate)),1))
install.packages("dplyr")
install.packages("plyr")
install.packages("psych")
install.packages("caret")
install.packages("randomForest")
install.packages("plyr")
install.packages("mlbench")
install.packages("glmnet")
library(glmnet)
library(psych)
library(mlbench)
library(caret)
install.packages("ggplot2")
library(ggplot2)
#Data
data("BostonHousing")
#Data
data("austres")
#Data
rm(austres)
setwd("D:/R Datasets/R codes and Datasets/Lasso Ridge")
getwd()
data <- read.csv("train.csv")
View(data)
train_data <- read.csv("train.csv")
test_data  <- read.csv("test.csv")
str(train_data)
data <- rbind(train_data,test_data)
str(train_data)
train_data$chas <- as.factor(train_data$chas)
test_data$chas  <- as.factor(test_data$chas)
str(train_data)
#Data
?BostonHousing
table(train_data$chas)
table(test_data$chas)
library(mlbench)
BostonHousing
?BostonHousing
library(glmnet)
library(psych)
library(mlbench)
library(caret)
library(ggplot2)
library(ggplot2)
data <- BostonHousing
data <- BostonHousing
data("BostonHousing") <- BostonHousing
data("BostonHousing")
data <- BostonHousing
str(data)
table(data$chas)
str(data)
pairs.panels(data[c(-4,-14)])
#Data Partition
set.seed(222)
ind <- sample(2,nrow(data),replace = T,prob = c(0.7,0.3))
train <- data[ind == 1]
train <- data[ind == 1,]
test  <- data[ind == 0,]
test  <- data[ind == 2,]
?`caret-internal`
caret
?trainControl()
#Custom control parameters
custom <- trainControl(method = "repeatedcv",number = 10,repeats = 5,verboseIter = T)
#linear Model
set.seed(234)
#linear Model
set.seed(1234)
lm <- train(medv ~.,train,method = 'lm',trControl = custom)
lm$results
lm
summary(lm)
plot(lm$finalModel)
plot(lm$finalModel)
#Ridge regression
set.seed(1234)
ridge <- train(medv~.,train,method = 'glmnet',
tuneGrid = expand.grid(alpha = 0,lamda = seq(0.0001,1,length = 5)),
trControl = custom)
ridge <- train(medv~.,
train,
method = 'glmnet',
tuneGrid = expand.grid(alpha = 0,
lamda = seq(0.0001,1,length = 5)),
trControl = custom)
library(glmnet)
library(psych)
library(mlbench)
library(caret)
library(ggplot2)
data("BostonHousing")
data <- BostonHousing
str(data)
pairs.panels(data[c(-4,-14)])
#Data Partition
set.seed(222)
ind <- sample(2,nrow(data),replace = T,prob = c(0.7,0.3))
train_data <- data[ind == 1,]
test_data  <- data[ind == 2,]
#Custom control parameters
custom <- trainControl(method = "repeatedcv",number = 10,repeats = 5,verboseIter = T)
#linear Model
set.seed(1234)
lm <- train(medv ~.,train_data,method = 'lm',trControl = custom)
lm$results
summary(lm)
plot(lm$finalModel)
method = 'glmnet',
tuneGrid = expand.grid(tuneGridalpha = 0,
lamda = seq(0.0001,1,length = 5)),
trControl = custom)
ridge <- train(medv~.,
train_data,
method = 'glmnet',tuneGrid = expand.grid(tuneGridalpha = 0,lamda = seq(0.0001,1,length = 5)),
trControl = custom)
#Ridge regression
set.seed(1234)
ridge <- train(train_data$medv,train_data,method = 'glmnet',
tuneGrid = expand.grid(aplha = 0,
lambda = seq(0.0001,1,length =5)),
trControl = custom)
ridge <- train(medv,train_data,method = 'glmnet',
tuneGrid = expand.grid(aplha = 0,
lambda = seq(0.0001,1,length =5)),
trControl = custom)
ridge <- train(medv ~.,train_data,method = 'glmnet',
tuneGrid = expand.grid(aplha = 0,
lambda = seq(0.0001,1,length =5)),
trControl = custom)
ridge <- train(medv ~.,train_data,method = 'glmnet',
tuneGrid = expand.grid(aplha = 0,
lambda = seq(0.0001,1,length =5)),
trControl = custom)
library(glmnet)
library(psych)
library(mlbench)
library(caret)
data("BostonHousing")
data <- BostonHousing
str(data)
pairs.panels(data[c(-4,-14)])
#Data Partition
set.seed(222)
ind <- sample(2,nrow(data),replace = T,prob = c(0.7,0.3))
train_data <- data[ind == 1,]
test_data  <- data[ind == 2,]
#Custom control parameters
custom <- trainControl(method = "repeatedcv",number = 10,repeats = 5,verboseIter = T)
#linear Model
set.seed(1234)
lm <- train(medv ~.,train_data,method = 'lm',trControl = custom)
lm$results
summary(lm)
plot(lm$finalModel)
lambda = seq(0.0001,1,length =5)),
trControl = custom)
ridge <- train(medv ~.,train_data,method = 'glmnet',
tuneGrid = expand.grid(aplha = 0,
lambda = seq(0.0001,1,length =5)),
trControl = custom)
ridge <- train(medv ~.,train_data,method = 'glmnet',trControl = custom)
print(ridge)
